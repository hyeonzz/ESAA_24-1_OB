{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeonzz/ESAA_24-1_OB/blob/session/3_15_%EB%AA%A8%EB%8D%B8%ED%9B%88%EB%A0%A8_%EC%84%B8%EC%85%98_%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **| 모델 훈련 연습 문제**\n",
        "___\n",
        "- 출처 : 핸즈온 머신러닝 Ch04 연습문제 1, 5, 9, 10\n",
        "- 개념 문제의 경우 텍스트 셀을 추가하여 정답을 적어주세요."
      ],
      "metadata": {
        "id": "zCu72vDHGMHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. 수백만 개의 특성을 가진 훈련 세트에서는 어떤 선형 회귀 알고리즘을 사용할 수 있을까요?**\n",
        "___\n"
      ],
      "metadata": {
        "id": "j3g-_Dq9GiuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "확률적 경사하강법, 미니배치 경사 하강법"
      ],
      "metadata": {
        "id": "vMeI_mdbbzJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. 배치 경사 하강법을 사용하고 에포크마다 검증 오차를 그래프로 나타내봤습니다. 검증 오차가 일정하게 상승되고 있다면 어떤 일이 일어나고 있는 걸까요? 이 문제를 어떻게 해결할 수 있나요?**\n",
        "___"
      ],
      "metadata": {
        "id": "-pDjW5XcHPOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "에포크마다 검증 에러가 지속적으로 상승한다면 한 가지 가능성은 학습률이 너무 높아 알고리즘이 발산하는 것일 수 있다. 훈련 에러도 올라간다면 이 문제가 확실하므로, 학습률을 낮추어야 한다. 하지만 훈련 에러가 증가하지 않는다면, 모델이 훈련 세트에 과대적합 되어 있는 것이므로 훈련을 멈춰야 한다.\n",
        "p.191"
      ],
      "metadata": {
        "id": "HdNhQwRieqd4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. 릿지 회귀를 사용했을 때 훈련 오차가 검증 오차가 거의 비슷하고 둘 다 높았습니다. 이 모델에는 높은 편향이 문제인가요, 아니면 높은 분산이 문제인가요? 규제 하이퍼파라미터 $\\alpha$를 증가시켜야 할까요 아니면 줄여야 할까요?**\n",
        "___"
      ],
      "metadata": {
        "id": "nM7JbsLoy7b7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "과소적합으로 인한 높은 편향. 하이퍼파라미터 $a$를 줄여야함."
      ],
      "metadata": {
        "id": "Qwxxm5DIfdeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. 다음과 같이 사용해야 하는 이유는?**\n",
        "___\n",
        "- 평범한 선형 회귀(즉, 아무런 규제가 없는 모델) 대신 릿지 회귀\n",
        "- 릿지 회귀 대신 라쏘 회귀\n",
        "- 라쏘 회귀 대신 엘라스틱넷"
      ],
      "metadata": {
        "id": "C8tARu-ZzOGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 규제가 약간 있는 것이 대부분 좋으므로 일반적으로 평범한 선형 회귀는 x - 규제가 있는 모델이 일반적으로 규제가 없는 모델보다 성능이 좋기 때문\n",
        "- 릿지가 기본이지만 쓰이는 특성이 몇 개뿐이라고 의심되면 라쏘나 엘라스틱넷이 나음. (라쏘와 엘라스틱넷은 불필요한 특성의 가중치를 0으로 만들어주기 때문)\n",
        "- 특성 수가 훈련 샘플 수보다 많거나 특성 몇 개가 강하게 연관되어 있을 때는 보통 라쏘보다는 엘라스틱넷이 나음."
      ],
      "metadata": {
        "id": "_uVI-WZsf8BD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **추가) 조기 종료를 사용한 배치 경사 하강법으로 iris 데이터를 활용해 소프트맥스 회귀를 구현해보세요(사이킷런은 사용하지 마세요)**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "QIZpOEYJVIAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "8pXDQ_fU8Nz0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load iris dataset\n",
        "iris = load_iris()"
      ],
      "metadata": {
        "id": "hDk5Bddbp-XS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = iris.data[:, (2,3)] # 꽃잎 길이, 꽃잎 너비\n",
        "y = iris[\"target\"]"
      ],
      "metadata": {
        "id": "1efecfpr0j-P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_b = np.c_[np.ones(len(X)),X]"
      ],
      "metadata": {
        "id": "Ms4_5iYI0aiV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta = np.random.randn(3,3)"
      ],
      "metadata": {
        "id": "nATL3QOG0luw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_b, y, test_size = 0.2, random_state=42)"
      ],
      "metadata": {
        "id": "wdLY10sb0sQ4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(categories='auto')\n",
        "y_train_ohe = encoder.fit_transform(y_train.reshape(-1, 1)).toarray()\n",
        "y_test_ohe = encoder.fit_transform(y_test.reshape(-1, 1)).toarray()"
      ],
      "metadata": {
        "id": "WvPknJGn04Uc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(z):\n",
        "   exps = np.exp(z)\n",
        "   exp_sum = np.sum(exps, axis=1, keepdims = True)\n",
        "   return exps/exp_sum"
      ],
      "metadata": {
        "id": "ZzMg-Oug1Ahk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ZDBXi2Nx1bNj"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}